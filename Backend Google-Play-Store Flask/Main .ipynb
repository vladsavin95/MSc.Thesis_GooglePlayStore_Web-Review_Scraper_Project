{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install libraries below using \"pip install\"\n",
    "#matplotlib==3.3.1 numpy==1.19.3 beautifulsoup4==4.9.3 selenium==3.141.0 vaderSentiment==3.3.2 wordcloud==1.8.1\n",
    "#nltk\n",
    "\n",
    "# library importing\n",
    "import json\n",
    "import platform\n",
    "import time\n",
    "import matplotlib\n",
    "import nltk\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# scrapping libraries importing\n",
    "from collections import OrderedDict  # dictionary subclass that remembers the order in which its contents are added\n",
    "from bs4 import BeautifulSoup  # scrape information from web pages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from PIL import Image\n",
    "from statistics import mean\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer  # sentiment analysis\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "\n",
    "# Gathering of reviews\n",
    "def merging_comment(html, filename):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    h3 = soup.find_all('h3')\n",
    "    user_review = None\n",
    "    for head in h3:\n",
    "        if 'User reviews' in str(head):\n",
    "            user_review = head\n",
    "\n",
    "    user_review_parent = user_review.find_parent()\n",
    "    review_area = user_review_parent.find('div', recursive=False)\n",
    "    reviews = review_area.find_all('div', recursive=False)\n",
    "\n",
    "    all_comments = []\n",
    "    for review in reviews:\n",
    "        text = review.find_all('div')[-1]\n",
    "        if text.text == 'Full Review':\n",
    "            text = review.find_all('div')[-2]\n",
    "\n",
    "        comment = text.text.strip()\n",
    "        comment = ' '.join(comment.split())\n",
    "        all_comments.append(comment)\n",
    "\n",
    "    # Sentiment analysis\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    negative_group = []\n",
    "    neutral_group = []\n",
    "    positive_group = []\n",
    "    sentiment_results = ''\n",
    "    all_percentage = []\n",
    "    for sentence in all_comments:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        negative_score = vs['neg']\n",
    "        neutral_score = vs['neu']\n",
    "        positive_score = vs['pos']\n",
    "        dict_percentage = {\n",
    "            'negative': negative_score * 100,\n",
    "            'neutral': neutral_score * 100,\n",
    "            'positive': positive_score * 100\n",
    "        }\n",
    "        all_percentage.append(dict_percentage)\n",
    "\n",
    "        # Conditioning & defining the 3 types of reviews: Negative, Neutral, Positive\n",
    "        if negative_score > neutral_score and negative_score > positive_score:\n",
    "            negative_group.append(sentence)\n",
    "        if neutral_score > negative_score and neutral_score > positive_score:\n",
    "            neutral_group.append(sentence)\n",
    "        if positive_score > negative_score and positive_score > neutral_score:\n",
    "            positive_group.append(sentence)\n",
    "\n",
    "        sentiment_results += sentence\n",
    "        sentiment_results += '\\n'\n",
    "        sentiment_results += 'Negative: {}, Neutral: {}, Positive: {}'.format(round(negative_score*100,2),\n",
    "                                                                              round(neutral_score*100,2),\n",
    "                                                                              round(positive_score*100,2))\n",
    "        sentiment_results += '\\n=========================================================\\n'\n",
    "\n",
    "    f = open('static/results/{}.txt'.format(filename + ' analyze results'), 'w+', encoding='utf-8')\n",
    "    f.write(sentiment_results)\n",
    "    f.close()\n",
    "\n",
    "    merged_negative_group = ' '.join(negative_group)\n",
    "    merged_neutral_group = ' '.join(neutral_group)\n",
    "    merged_positive_group = ' '.join(positive_group)\n",
    "\n",
    "    return merged_negative_group, merged_neutral_group, merged_positive_group, all_percentage\n",
    "\n",
    "\n",
    "# Organize string from big to small and alphabetically\n",
    "def word_count(str):\n",
    "    counts = dict()\n",
    "    words = str.split()\n",
    "\n",
    "    # Count the occurrences of each word in a given sentence\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "def get_mask_file(mask):\n",
    "    if mask == \"heart\":\n",
    "        return \"img/heart.png\"\n",
    "    elif mask == \"cloud\":\n",
    "        return \"img/cloud.png\"\n",
    "    elif mask == \"android\":\n",
    "        return \"img/android.png\"\n",
    "    elif mask == \"comment\":\n",
    "        return \"img/comment.png\"\n",
    "    elif mask == \"diamond\":\n",
    "        return \"img/diamond.png\"\n",
    "    elif mask == \"like\":\n",
    "        return \"img/like.png\"\n",
    "    elif mask == \"location\":\n",
    "        return \"img/location.png\"\n",
    "    elif mask == \"star\":\n",
    "        return \"img/star.png\"\n",
    "    elif mask == \"user\":\n",
    "        return \"img/user.png\"\n",
    "    else:\n",
    "        return \"img/heart.png\"\n",
    "\n",
    "\n",
    "# creating the wordcloud\n",
    "def create_wordcloud(config, final_words, filename, mask, color, font, maxwords, corpus, custom_blocked_words):\n",
    "    print('creating wordcloud.....')\n",
    "\n",
    "    final_words_updated = []\n",
    "    for word in final_words:\n",
    "        word = word.replace('.', '').replace(',', '').replace('?', '').replace('!', '').lower()\n",
    "        final_words_updated.append(word)\n",
    "\n",
    "    # Filtering word by blocked words\n",
    "    f = open(\"blocked.txt\", \"r\")\n",
    "    blocked_words = [line.replace('\\n', '') for line in f.readlines() if line != '\\n']\n",
    "    blocked_words.extend(custom_blocked_words)\n",
    "    blocked_words.extend(nltk.corpus.stopwords.words(corpus))\n",
    "    final_words = [word for word in final_words_updated if word not in blocked_words]\n",
    "\n",
    "    # Defining dimensions of wordcloud\n",
    "    mask = get_mask_file(mask)\n",
    "    background_color = config['background_color']\n",
    "    max_words = config['max_words']\n",
    "    words = ' '.join(final_words[0:max_words])\n",
    "    if mask is not None:\n",
    "        mask = np.array(Image.open(mask))\n",
    "\n",
    "    # Generate a word cloud image\n",
    "    wordcloud = WordCloud(background_color=background_color, max_words=maxwords, mask=mask, width=1920, font_path=font, height=1080).generate(words)\n",
    "\n",
    "    if mask is not None:\n",
    "        image_colors = ImageColorGenerator(mask)\n",
    "        plt.figure(figsize=(20, 10), facecolor='k')\n",
    "        if color is None:\n",
    "            plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "        else:\n",
    "            plt.imshow(wordcloud.recolor(colormap=color))\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad=0)\n",
    "    else:\n",
    "        plt.figure(figsize=(20, 10), facecolor='k')\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad=0)\n",
    "\n",
    "    # store to file\n",
    "    plt.savefig(\"static/results/{}.png\".format(filename), facecolor='k', bbox_inches='tight')\n",
    "\n",
    "    print('image saved')\n",
    "    return f\"static/results/{filename}.png\"\n",
    "\n",
    "\n",
    "def histogram_generator(all_percentage, filename):\n",
    "    print('creating histogram....')\n",
    "    negative_average = round(mean([data['negative'] for data in all_percentage]), 1)\n",
    "    neutral_average = round(mean([data['neutral'] for data in all_percentage]), 1)\n",
    "    positive_average = round(mean([data['positive'] for data in all_percentage]), 1)\n",
    "\n",
    "    labels = []\n",
    "    numbers = []\n",
    "\n",
    "    analize_results = {\n",
    "        'negative': negative_average,\n",
    "        'neutral': neutral_average,\n",
    "        'positive': positive_average\n",
    "    }\n",
    "\n",
    "    for key, value in analize_results.items():\n",
    "        labels.append(key)\n",
    "        numbers.append(value)\n",
    "\n",
    "    index = np.arange(len(labels))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.barh(index, numbers)\n",
    "    for i, v in enumerate(numbers):\n",
    "        plt.text(v + 0.2, i, str(v), color='black')\n",
    "    plt.yticks(index, labels, fontsize=10, rotation=0)\n",
    "    plt.xlabel('Percentage', fontsize=10)\n",
    "    plt.title(\"total comments: {}\".format(len(all_percentage)))\n",
    "\n",
    "    plt.savefig(\"static/results/{}.png\".format(filename + ' percentage'))\n",
    "    \n",
    "    return f\"static/results/{filename} percentage.png\"\n",
    "\n",
    "\n",
    "def run_analysis(app_link, filename, mask, color, font, maxwords, corpus, custom_blocked_words, data_response={}, change_mask=False):\n",
    "    # opening config.json\n",
    "    # To view open in folder config.json - location of the app link and wordcloud info\n",
    "    # For HTML link for config.json: In Chrome access developer Tools function of the browser provides us access to the HTML structure of a web page. To access the developer tool function, right-click on whatever element you want to examine, select inspect, and it will take you right to the HTML tag of that element.\n",
    "    final_result = {}\n",
    "    with open('config.json') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    if change_mask:\n",
    "        final_words_response = data_response['final_words']\n",
    "        histogram_response = data_response['search_results']['histogram_image']\n",
    "\n",
    "        try:\n",
    "            final_result[\"negative_wordcloud_image\"] = create_wordcloud(config, final_words_response['negative'], filename + '_negative', mask, color, font, maxwords, corpus, custom_blocked_words)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            final_result[\"neutral_wordcloud_image\"] = create_wordcloud(config, final_words_response['neutral'],  filename + '_neutral', mask, color, font, maxwords, corpus, custom_blocked_words)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            final_result[\"positive_wordcloud_image\"] = create_wordcloud(config, final_words_response['positive'],  filename + '_positive', mask, color, font, maxwords, corpus, custom_blocked_words)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            final_result[\"histogram_image\"] = histogram_response\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return final_words_response, final_result\n",
    "\n",
    "\n",
    "    # OS Chrome usage on MAC, Windows and Linux - vital for automatic scrolling when scrapping reviews\n",
    "    operating_system = platform.system()\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    try:\n",
    "        if operating_system == 'Linux':\n",
    "            driver = webdriver.Chrome('./chromedriver-linux', options=chrome_options)\n",
    "        if operating_system == 'Darwin':\n",
    "            driver = webdriver.Chrome('./chromedriver-mac', options=chrome_options)\n",
    "        if operating_system == 'Windows':\n",
    "            driver = webdriver.Chrome('./chromedriver-windows.exe', options=chrome_options)\n",
    "\n",
    "        # scrolling in Chrome\n",
    "        driver.maximize_window()\n",
    "        driver.get(app_link)\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "\n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        show_more_count = config['show_more_count']\n",
    "        count = 0\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            # Wait to load page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            print('wait 5 seconds to next scroll')\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                show_more = driver.find_elements_by_xpath(\"//*[contains(text(), 'Show More')]\")\n",
    "                if len(show_more)>0:\n",
    "                    show_more = show_more[-1]\n",
    "                    if count >= show_more_count:\n",
    "                        break\n",
    "                    show_more.click()\n",
    "                    count += 1\n",
    "                    continue\n",
    "\n",
    "                break\n",
    "\n",
    "            last_height = new_height\n",
    "\n",
    "        html = driver.page_source\n",
    "        driver.close()\n",
    "    except Exception:\n",
    "        driver.close()\n",
    "        raise\n",
    "\n",
    "    merged_negative, merged_neutral, merged_positive, all_percentage = merging_comment(html, filename)\n",
    "\n",
    "\n",
    "    final_words_group = {}\n",
    "    # negative process\n",
    "    print('negative process....')\n",
    "    results = word_count(merged_negative)\n",
    "    d_sorted_by_value = OrderedDict(sorted(results.items(), key=lambda x: x[1], reverse=True))\n",
    "    final_words = []\n",
    "    for k, v in d_sorted_by_value.items():\n",
    "        final_words.append(k)\n",
    "    try:\n",
    "        final_result[\"negative_wordcloud_image\"] = create_wordcloud(config, final_words, filename + '_negative', mask, color, font, maxwords, corpus, custom_blocked_words)\n",
    "    except Exception:\n",
    "        pass\n",
    "    final_words_group['negative'] = final_words\n",
    "\n",
    "    # neutral process\n",
    "    print('neutral process....')\n",
    "    results = word_count(merged_neutral)\n",
    "    d_sorted_by_value = OrderedDict(sorted(results.items(), key=lambda x: x[1], reverse=True))\n",
    "    final_words = []\n",
    "    for k, v in d_sorted_by_value.items():\n",
    "        final_words.append(k)\n",
    "    try:\n",
    "        final_result[\"neutral_wordcloud_image\"] = create_wordcloud(config, final_words, filename + '_neutral', mask, color, font, maxwords, corpus, custom_blocked_words)\n",
    "    except Exception:\n",
    "        pass\n",
    "    final_words_group['neutral'] = final_words\n",
    "\n",
    "    # positive process\n",
    "    print('positive process....')\n",
    "    results = word_count(merged_positive)\n",
    "    d_sorted_by_value = OrderedDict(sorted(results.items(), key=lambda x: x[1], reverse=True))\n",
    "    final_words = []\n",
    "    for k, v in d_sorted_by_value.items():\n",
    "        final_words.append(k)\n",
    "    try:\n",
    "        final_result[\"positive_wordcloud_image\"] = create_wordcloud(config, final_words, filename + '_positive', mask, color, font, maxwords, corpus, custom_blocked_words)\n",
    "    except Exception:\n",
    "        pass\n",
    "    final_words_group['positive'] = final_words\n",
    "\n",
    "    # Generate histogram\n",
    "    final_result[\"histogram_image\"] = histogram_generator(all_percentage, filename)\n",
    "\n",
    "    return final_words_group, final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
